{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Markov_story_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1toZysNWuiTmKC3sdM9zmPHrJMPMcYdeH",
      "authorship_tag": "ABX9TyOy9NH3xavRExIpU4mHxGGG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sh-shrey/AI/blob/main/Markov_story_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b2KyAsPAL9n"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APScZ1-vBpjb",
        "outputId": "76929885-f699-47ad-89f2-82b97abcd435"
      },
      "source": [
        "story_path = \"/content/drive/MyDrive/Colab Notebooks/sherlock/sherlock/\"\n",
        "\n",
        "def read_all_stories(story_path):\n",
        "    txt = []\n",
        "    for _, _, files in os.walk(story_path):\n",
        "        for file in files:\n",
        "            with open(story_path+file) as f:\n",
        "                for line in f:\n",
        "                    line = line.strip()\n",
        "                    if line=='----------': break\n",
        "                    if line!='':txt.append(line)\n",
        "    return txt\n",
        "        \n",
        "stories = read_all_stories(story_path)\n",
        "print(\"number of lines = \", len(stories))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of lines =  215021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyozhchhCmYW"
      },
      "source": [
        "cleaning the text\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1-8SONmCoe-",
        "outputId": "da2f95a8-a4f2-42d8-abd6-5326d1bc1942"
      },
      "source": [
        "def clean_txt(txt):\n",
        "    cleaned_txt = []\n",
        "    for line in txt:\n",
        "        line = line.lower()\n",
        "        line = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", line)\n",
        "        tokens = word_tokenize(line)\n",
        "        words = [word for word in tokens if word.isalpha()]\n",
        "        cleaned_txt+=words\n",
        "    return cleaned_txt\n",
        "\n",
        "cleaned_stories = clean_txt(stories)\n",
        "print(\"number of words = \", len(cleaned_stories))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of words =  2332247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWuIJUq4MixT",
        "outputId": "7a892e44-e4e6-41bf-fd21-826cfe6e1f03"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HILtz6D_Dlo3"
      },
      "source": [
        "def make_markov_model(cleaned_stories, n_gram=2):\n",
        "    markov_model = {}\n",
        "    for i in range(len(cleaned_stories)-n_gram-1):\n",
        "        curr_state, next_state = \"\", \"\"\n",
        "        for j in range(n_gram):\n",
        "            curr_state += cleaned_stories[i+j] + \" \"\n",
        "            next_state += cleaned_stories[i+j+n_gram] + \" \"\n",
        "        curr_state = curr_state[:-1]\n",
        "        next_state = next_state[:-1]\n",
        "        if curr_state not in markov_model:\n",
        "            markov_model[curr_state] = {}\n",
        "            markov_model[curr_state][next_state] = 1\n",
        "        else:\n",
        "            if next_state in markov_model[curr_state]:\n",
        "                markov_model[curr_state][next_state] += 1\n",
        "            else:\n",
        "                markov_model[curr_state][next_state] = 1\n",
        "    \n",
        "    # calculating transition probabilities\n",
        "    for curr_state, transition in markov_model.items():\n",
        "        total = sum(transition.values())\n",
        "        for state, count in transition.items():\n",
        "            markov_model[curr_state][state] = count/total\n",
        "    return markov_model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBFNc90hD91v"
      },
      "source": [
        "markov_model = make_markov_model(cleaned_stories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFeC0estEC5N",
        "outputId": "a09ca049-3c58-4414-973f-c60b16bde60d"
      },
      "source": [
        "print(\"number of states = \", len(markov_model.keys()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of states =  208716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r2_8e-sEGvI",
        "outputId": "f8320457-2b0a-4df4-ebff-19b4faf7c96f"
      },
      "source": [
        "print(\"All possible transitions from 'the game' state: \\n\")\n",
        "print(markov_model['the game'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All possible transitions from 'the game' state: \n",
            "\n",
            "{'is afoot': 0.036036036036036036, 'was up': 0.09009009009009009, 'was in': 0.02702702702702703, 'is hardly': 0.02702702702702703, 'would have': 0.036036036036036036, 'is up': 0.06306306306306306, 'is and': 0.036036036036036036, 'in their': 0.036036036036036036, 'was whist': 0.036036036036036036, 'in that': 0.036036036036036036, 'the lack': 0.036036036036036036, 'for all': 0.06306306306306306, 'may wander': 0.02702702702702703, 'now a': 0.02702702702702703, 'my own': 0.02702702702702703, 'at any': 0.02702702702702703, 'mr holmes': 0.02702702702702703, 'ay whats': 0.02702702702702703, 'my friend': 0.02702702702702703, 'fairly by': 0.02702702702702703, 'is not': 0.02702702702702703, 'was not': 0.02702702702702703, 'was afoot': 0.036036036036036036, 'for the': 0.036036036036036036, 'your letter': 0.02702702702702703, 'worth it': 0.02702702702702703, 'you are': 0.02702702702702703, 'i am': 0.02702702702702703, 'now count': 0.02702702702702703}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UGhRh-uERSV"
      },
      "source": [
        "def generate_story(markov_model, limit=100, start='my god'):\n",
        "    n = 0\n",
        "    curr_state = start\n",
        "    next_state = None\n",
        "    story = \"\"\n",
        "    story+=curr_state+\" \"\n",
        "    while n<limit:\n",
        "        next_state = random.choices(list(markov_model[curr_state].keys()),\n",
        "                                    list(markov_model[curr_state].values()))\n",
        "        \n",
        "        curr_state = next_state[0]\n",
        "        story+=curr_state+\" \"\n",
        "        n+=1\n",
        "    return story"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofwip-FWEVME",
        "outputId": "ed46b56f-c6de-436f-8f17-65063c1686f7"
      },
      "source": [
        "for i in range(20):\n",
        "    print(str(i)+\". \", generate_story(markov_model, start=\"the subject\", limit=8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.  the subject for to do it i asked after we have heard well state your case to be \n",
            "1.  the subject i had formed from the newspaper reports were entirely erroneous conclusion which shows my dear watson \n",
            "2.  the subject very naturally mr ferguson but human nature is weak i wish you therefore to think that \n",
            "3.  the subject is very late and when he was a knife i glanced at my watch was dark \n",
            "4.  the subject of the accused disappears and yet no friends whom i suspected i read in his face \n",
            "5.  the subject for to do it so well now that such an insult again i have said on \n",
            "6.  the subject but there was much puzzled by something which brought him the coronet to someone in the \n",
            "7.  the subject of the jaw it is surely nothing in life more painful than his violence or his \n",
            "8.  the subject said holmes laying aside his lens not only my honour my gems and my heart set \n",
            "9.  the subject have you dropped from his cigar then suddenly came a gentle flow of soothing explanation from \n",
            "10.  the subject but there was no you say very good sir i believe that he had brought with \n",
            "11.  the subject you are on his leg what do you think of what would either of rachel howells \n",
            "12.  the subject which were on no account to pass the dollars out into circulation then he has a \n",
            "13.  the subject some weeks before from godfrey milner and lord balmoral so much for my nerves tingled with \n",
            "14.  the subject turn over those papers and arrange them for between friends my brother i should have thought \n",
            "15.  the subject that trick of staining the fishes scales of a delicate operation i knew that i have \n",
            "16.  the subject of this hedge concealed from the house and tear about the garden path for some time \n",
            "17.  the subject said holmes springing to his feet and his wife a treat had taken two upper circle \n",
            "18.  the subject some weeks before from godfrey milner and lord balmoral so much for me what was false \n",
            "19.  the subject without any preliminary sound in the air his gray clothes and jerky zigzag irregular progress made \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJlIC3fHNA_T",
        "outputId": "9a5a72d5-f9d4-47a4-aebe-3fb4e9f92408"
      },
      "source": [
        "print(generate_story(markov_model,start='the case',limit=100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the case and it was a pale man with sandy whiskers rose up from him and he walked in that dark grimy apartment which looked out with three barges in tow blundered in between us it was the cause of death my correspondence however is as i hope to get back to business watson would you mind touching the bell he handed over the back garden wall like the cowardly dogs follow me gentlemen i will look he whipped out his lens and then i stopped and waited their time until they could set him to remember that a stonemason named slater walking from forest row in a stately manner he departed for europe i made a note which made me walk in here as a single man should know it well we have established a considerable though not a married man and have it out of the profession which has become a singularly dark one the landlord pricked up his ears at every siding and they were talking a sudden cry of pain from the planks and his beady eyes gleaming out of the grate there was no one not miss it for six it is as plain as i can \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}